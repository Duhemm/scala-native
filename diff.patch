commit 971c8ad0f3d3cfe97e90082ac97458b412960440
Merge: 1459943 3d8c3de
Author: Martin Duhem <martin.duhem@gmail.com>
Date:   Thu Dec 8 13:08:07 2016 +0100

    Testing, benchmarks, stuff
    
    erge branch 'wip/more-testing' into wip/inline-caching-with-tests

diff --cc benchmarks/src/main/scala/benchmarks/Benchmark.scala
index 6790ac2,b5ad82c..32730b9
--- a/benchmarks/src/main/scala/benchmarks/Benchmark.scala
+++ b/benchmarks/src/main/scala/benchmarks/Benchmark.scala
@@@ -41,13 -41,6 +41,13 @@@ abstract class Benchmark[T] 
    def run(): T
    def check(t: T): Boolean
  
 +  def iterations(): Int = {
 +    // Run once to estimate how long this benchmark takes
-     val nsPerBenchmark = 3e9.toLong
++    val nsPerBenchmark = 3e10.toLong
 +    val timeEstimate   = estimateTime()
 +    Math.max(1, (nsPerBenchmark / timeEstimate).toInt)
 +  }
 +
    private class BenchmarkDisabledException extends Exception
    final def disableBenchmark(): Nothing = throw new BenchmarkDisabledException
  
diff --cc benchmarks/src/main/scala/benchmarks/Main.scala
index c0f6001,0fa3497..ea192b8
--- a/benchmarks/src/main/scala/benchmarks/Main.scala
+++ b/benchmarks/src/main/scala/benchmarks/Main.scala
@@@ -3,16 -3,28 +3,16 @@@ package benchmark
  import java.lang.System.exit
  
  object Main {
 -
 -  val nsPerBenchmark = 3e9.toLong
 -
    def main(args: Array[String]): Unit = {
 -
--    val benchmarks = Discover.discovered
++    val benchmarks = Seq(new richards.RichardsBenchmark()) // Discover.discovered
  
      val success =
 -      benchmarks forall { bench =>
 -        // Run once to estimate how long this benchmark takes
 -        val timeEstimate = bench.estimateTime()
 -        val iterations   = (nsPerBenchmark / timeEstimate).toInt
 -
 -        val result = bench.loop(iterations)
 +      benchmarks.forall { bench =>
 +        val result = bench.loop(bench.iterations)
          println(result)
 -
 -        // Sleep between test to avoid error (???)
 -        Thread.sleep(50)
 -
          result.success
        }
  
--    if (success) exit(0) else exit(1)
++    if (!success) exit(1)
    }
  }
diff --cc benchmarks/src/main/scala/deltablue/DeltaBlueBenchmark.scala
index ac6d519,ac6d519..749b12d
--- a/benchmarks/src/main/scala/deltablue/DeltaBlueBenchmark.scala
+++ b/benchmarks/src/main/scala/deltablue/DeltaBlueBenchmark.scala
@@@ -49,8 -49,8 +49,8 @@@ import scala.collection.mutable.{ArrayB
  class DeltaBlueBenchmark extends benchmarks.Benchmark[Unit] {
  
    override def run(): Unit = {
--    chainTest(100)
--    projectionTest(100)
++    chainTest(1000)
++    projectionTest(1000)
    }
  
    override def check(t: Unit): Boolean =
diff --cc build.sbt
index a6c1d05,a998af8..9c14d25
--- a/build.sbt
+++ b/build.sbt
@@@ -372,15 -394,25 +394,47 @@@ lazy val benchmarks 
      )
      .enablePlugins(ScalaNativePlugin)
  
+ lazy val testingCompilerInterface =
+   project
+     .in(file("testing-compiler-interface"))
+     .settings(libSettings)
+     .settings(
+       crossPaths := false,
+       crossVersion := CrossVersion.Disabled,
+       autoScalaLibrary := false
+     )
+ 
+ lazy val testingCompiler =
+   project
+     .in(file("testing-compiler"))
+     .settings(libSettings)
+     .settings(noPublishSettings)
+     .settings(
+       libraryDependencies ++= Seq(
+         "org.scala-lang" % "scala-compiler" % scalaVersion.value,
+         "org.scala-lang" % "scala-reflect"  % scalaVersion.value
+       )
+     )
+     .dependsOn(testingCompilerInterface, nativelib)
++
 +commands += Command.command("bench") { state =>
 +  "set nativeProfileDispatch in benchmarks := false" ::
 +    "set nativeProfileInfo in benchmarks := None" ::
 +      "benchmarks/run" ::
 +          "set nativeProfileDispatch in benchmarks := true" ::
 +            """set nativeProfileInfo in benchmarks := Some(file("/Users/martin/Desktop/bench-dump/dispatch.txt"))""" ::
 +              "benchmarks/run" ::
 +                "set nativeProfileDispatch in benchmarks := false" ::
-                   "benchmarks/run" ::
-                     state
++                  "set nativeInlineCachingMaxCandidates in benchmarks := 1" ::
++                    "benchmarks/run" ::
++                      "set nativeInlineCachingMaxCandidates in benchmarks := 1" ::
++                        "benchmarks/run" ::
++                          "set nativeInlineCachingMaxCandidates in benchmarks := 3" ::
++                            "benchmarks/run" ::
++                              "set nativeInlineCachingMaxCandidates in benchmarks := 4" ::
++                                "benchmarks/run" ::
++                                  "set nativeInlineCachingMaxCandidates in benchmarks := 5" ::
++                                    "benchmarks/run" ::
++                                      state
 +
 +}
diff --cc llvm-tools/src/main/scala/scala/scalanative/llvm/LLVM.scala
index 0000000,b02f7b0..9a6a1ec
mode 000000,100644..100644
--- a/llvm-tools/src/main/scala/scala/scalanative/llvm/LLVM.scala
+++ b/llvm-tools/src/main/scala/scala/scalanative/llvm/LLVM.scala
@@@ -1,0 -1,158 +1,159 @@@
+ package scala.scalanative
+ package llvm
+ 
+ import java.io.File
+ 
+ import scala.sys.process.{Process, ProcessLogger}
+ import scala.util.Try
+ 
+ import System.{lineSeparator => nl}
+ 
+ object LLVM {
+ 
+   private def abs(file: File): String =
+     file.getAbsolutePath
+ 
+   private def running(command: Seq[String]): String =
 -    "running" + nl + command.mkString(nl + "\t")
++    ""
++    // "running" + nl + command.mkString(nl + "\t")
+ 
+   private def getFiles(base: File, filter: File => Boolean): Seq[File] =
+     (if (filter(base)) Seq(base) else Seq()) ++
+       (Option(base.listFiles()) getOrElse Array.empty flatMap (getFiles(
+         _,
+         filter)))
+ 
+   private[scalanative] def discover(
+       binaryName: String,
+       binaryVersions: Seq[(String, String)]): File = {
+ 
+     val docInstallUrl =
+       "http://scala-native.readthedocs.io/en/latest/user/setup.html#installing-llvm-clang-and-boehm-gc"
+ 
+     val envName =
+       if (binaryName == "clang") "CLANG"
+       else if (binaryName == "clang++") "CLANGPP"
+       else binaryName
+ 
+     sys.env.get(s"${envName}_PATH") match {
+       case Some(path) => new File(path)
+       case None => {
+         val binaryNames = binaryVersions.flatMap {
+           case (major, minor) =>
+             Seq(s"$binaryName$major$minor", s"$binaryName-$major.$minor")
+         } :+ binaryName
+ 
+         Process("which" +: binaryNames).lines_!
+           .map(new File(_))
+           .headOption
+           .getOrElse {
+             throw new Exception(
+               s"no ${binaryNames.mkString(", ")} found in $$PATH. Install clang ($docInstallUrl)")
+           }
+       }
+     }
+   }
+ 
+   private[scalanative] lazy val includes = {
+     val includedir =
+       Try(Process("llvm-config --includedir").lines_!.toSeq)
+         .getOrElse(Seq.empty)
+     ("/usr/local/include" +: includedir).map(s => s"-I$s")
+   }
+ 
+   private[scalanative] lazy val libs = {
+     val libdir =
+       Try(Process("llvm-config --libdir").lines_!.toSeq).getOrElse(Seq.empty)
+     ("/usr/local/lib" +: libdir).map(s => s"-L$s")
+   }
+ 
+   /** Compiles *.c[pp] in `cwd`. */
+   def compileCSources(clang: File,
+                       clangpp: File,
+                       cwd: File,
+                       logger: ProcessLogger): Boolean = {
+     val cpaths     = getFiles(cwd, _.getName endsWith ".c").map(abs)
+     val cpppaths   = getFiles(cwd, _.getName endsWith ".cpp").map(abs)
+     val compilec   = abs(clang) +: (LLVM.includes ++ ("-c" +: cpaths))
+     val compilecpp = abs(clangpp) +: (LLVM.includes ++ ("-c" +: cpppaths))
+ 
+     logger.out(running(compilec))
+     val cExit = Process(compilec, cwd) ! logger
+ 
+     logger.out(running(compilecpp))
+     val cppExit = Process(compilecpp, cwd) ! logger
+ 
+     cExit == 0 && cppExit == 0
+   }
+ 
+   /** Compiles application and runtime llvm ir file to binary using clang. */
+   private[scalanative] def compileLl(clangpp: File,
+                                      target: File,
+                                      nativelib: File,
+                                      appll: File,
+                                      binary: File,
+                                      links: Seq[String],
+                                      linkage: Map[String, String],
+                                      opts: Seq[String],
+                                      logger: ProcessLogger): Unit = {
+     val outpath = abs(binary)
+     val apppath = abs(appll)
+     val opaths  = getFiles(nativelib, _.getName endsWith ".o").map(abs)
+     val paths   = apppath +: opaths
+     val linkopts = links.zip(links.map(linkage.get(_))).flatMap {
+       case (name, Some("static"))         => Seq("-static", "-l", name)
+       case (name, Some("dynamic") | None) => Seq("-l", name)
+       case (name, Some(kind)) =>
+         throw new Exception(s"uknown linkage kind $kind for $name")
+     }
+     val flags   = Seq("-o", outpath) ++ linkopts ++ opts
+     val compile = abs(clangpp) +: (flags ++ paths)
+ 
+     logger.out(running(compile))
+ 
+     Process(compile, target) ! logger
+   }
+ 
+   /**
+    * Tests whether the clang compiler is recent enough.
+    * <p/>
+    * This is determined through looking up a built-in #define which is
+    * more reliable than testing for a specific version.
+    * <p/>
+    * It might be better to use feature checking macros:
+    * http://clang.llvm.org/docs/LanguageExtensions.html#feature-checking-macros
+    */
+   private[scalanative] def checkThatClangIsRecentEnough(
+       pathToClangBinary: File): Unit = {
+     def maybeFile(f: File) = f match {
+       case file if file.exists => Some(abs(file))
+       case none                => None
+     }
+ 
+     def definesBuiltIn(
+         pathToClangBinary: Option[String]): Option[Seq[String]] = {
+       def commandLineToListBuiltInDefines(clang: String) =
+         Process(Seq("echo", "")) #| Seq(clang, "-dM", "-E", "-")
+       def splitIntoLines(s: String)      = s.split(f"%n")
+       def removeLeadingDefine(s: String) = s.substring(s.indexOf(' ') + 1)
+ 
+       for {
+         clang <- pathToClangBinary
+         output = commandLineToListBuiltInDefines(clang).!!
+         lines  = splitIntoLines(output)
+       } yield lines map removeLeadingDefine
+     }
+ 
+     val clang                = maybeFile(pathToClangBinary)
+     val defines: Seq[String] = definesBuiltIn(clang).to[Seq].flatten
+     val clangIsRecentEnough =
+       defines.contains("__DECIMAL_DIG__ __LDBL_DECIMAL_DIG__")
+ 
+     if (!clangIsRecentEnough) {
+       throw new Exception(s"No recent installation of clang found " +
+         s"at $pathToClangBinary.\nSee https://github.com/scala-native/scala-" +
+         s"native/blob/master/docs/building.md for details.")
+     }
+   }
+ 
+ }
diff --cc nativelib/src/main/resources/profileinsts.cpp
index be3c543,0000000..1eb8205
mode 100644,000000..100644
--- a/nativelib/src/main/resources/profileinsts.cpp
+++ b/nativelib/src/main/resources/profileinsts.cpp
@@@ -1,45 -1,0 +1,57 @@@
 +#include <stdlib.h>
 +#include <stdio.h>
 +#include <string>
 +#include "CountingMap.hpp"
 +#include "gc.h"
 +
 +CountingMap insts;
 +
 +extern "C" {
 +	void log_call() {
 +		insts.insert_occ("call", 1);
 +	}
 +
 +	void log_load() {
 +		insts.insert_occ("load", 1);
 +	}
 +
 +	void log_store() {
 +		insts.insert_occ("store", 1);
 +	}
 +
 +	void log_elem() {
 +		insts.insert_occ("elem", 1);
 +	}
 +
 +	void log_extract() {
 +		insts.insert_occ("extract", 1);
 +	}
 +
 +	void log_insert() {
 +		insts.insert_occ("insert", 1);
 +	}
 +
 +	void log_stackalloc() {
 +		insts.insert_occ("stackalloc", 1);
 +	}
 +
++	void log_bin() {
++		insts.insert_occ("bin", 1);
++	}
++
++	void log_comp() {
++		insts.insert_occ("comp", 1);
++	}
++
++	void log_conv() {
++		insts.insert_occ("conv", 1);
++	}
++
 +	void log_select() {
 +		insts.insert_occ("select", 1);
 +	}
 +
 +	void profile_insts_dump() {
 +		insts.print(stdout);
 +	}
 +}
diff --cc nir/src/main/scala/scala/scalanative/nir/Global.scala
index 04b9e9e,04b9e9e..3f1d14c
--- a/nir/src/main/scala/scala/scalanative/nir/Global.scala
+++ b/nir/src/main/scala/scala/scalanative/nir/Global.scala
@@@ -23,6 -23,6 +23,8 @@@ sealed abstract class Global 
      case Global.Member(n, id) => Global.Member(n, s"$tag.$id")
      case _                    => util.unreachable
    }
++
++  override def toString(): String = id
  }
  object Global {
    final case object None extends Global {
diff --cc nscplugin/src/main/scala/scala/scalanative/nscplugin/NirCodeGen.scala
index 74d172f,1df729c..c2fe049
--- a/nscplugin/src/main/scala/scala/scalanative/nscplugin/NirCodeGen.scala
+++ b/nscplugin/src/main/scala/scala/scalanative/nscplugin/NirCodeGen.scala
@@@ -868,6 -868,6 +868,16 @@@ abstract class NirCodeGe
          case _ =>
            val sym = fun.symbol
  
++          if (null eq sym) {
++            println("#" * 181)
++            println("WTF: " + fun)
++            println("-" * 181)
++            println(app)
++            println("fun.sym = " + fun.symbol)
++            println("#" * 181)
++            ???
++          }
++
            if (sym.isLabel) {
              genApplyLabel(app, focus)
            } else if (scalaPrimitives.isPrimitive(sym)) {
diff --cc sbt-scala-native/src/main/scala/scala/scalanative/sbtplugin/ScalaNativePluginInternal.scala
index bd0f2e1,0b92d07..47ef2be
--- a/sbt-scala-native/src/main/scala/scala/scalanative/sbtplugin/ScalaNativePluginInternal.scala
+++ b/sbt-scala-native/src/main/scala/scala/scalanative/sbtplugin/ScalaNativePluginInternal.scala
@@@ -35,48 -38,8 +38,9 @@@ object ScalaNativePluginInternal 
    private def abs(file: File): String =
      file.getAbsolutePath
  
-   private def discover(binaryName: String,
-                        binaryVersions: Seq[(String, String)]): File = {
- 
-     val docInstallUrl =
-       "http://scala-native.readthedocs.io/en/latest/user/setup.html#installing-llvm-clang-and-boehm-gc"
- 
-     val envName =
-       if (binaryName == "clang") "CLANG"
-       else if (binaryName == "clang++") "CLANGPP"
-       else binaryName
- 
-     sys.env.get(s"${envName}_PATH") match {
-       case Some(path) => file(path)
-       case None => {
-         val binaryNames = binaryVersions.flatMap {
-           case (major, minor) =>
-             Seq(s"$binaryName$major$minor", s"$binaryName-$major.$minor")
-         } :+ binaryName
- 
-         Process("which" +: binaryNames).lines_!
-           .map(file(_))
-           .headOption
-           .getOrElse {
-             throw new MessageOnlyException(
-               s"no ${binaryNames.mkString(", ")} found in $$PATH. Install clang ($docInstallUrl)")
-           }
-       }
-     }
-   }
+   private def running(command: Seq[String]): String =
 -    "running" + nl + command.mkString(nl + "\t")
++    ""
++    // "running" + nl + command.mkString(nl + "\t")
  
    private def reportLinkingErrors(unresolved: Seq[nir.Global],
                                    logger: Logger): Nothing = {
@@@ -219,14 -133,11 +134,14 @@@
        "org.scala-native" % "nscplugin" % nativeVersion cross CrossVersion.full),
      nativeLibraryLinkage := Map(),
      nativeSharedLibrary := false,
 +    nativeProfileDispatch := false,
 +    nativeProfileInfo := None,
 +    nativeInlineCachingMaxCandidates := 2,
      nativeClang := {
-       discover("clang", Seq(("3", "8"), ("3", "7")))
+       LLVM.discover("clang", Seq(("3", "8"), ("3", "7")))
      },
      nativeClangPP := {
-       discover("clang++", Seq(("3", "8"), ("3", "7")))
+       LLVM.discover("clang++", Seq(("3", "8"), ("3", "7")))
      },
      nativeClangOptions := {
        // We need to add `-lrt` for the POSIX realtime lib, which doesn't exist
diff --cc testing-compiler/src/main/scala/scalanative/compiler/NIRCompiler.scala
index 0000000,5c674d9..1753616
mode 000000,100644..100644
--- a/testing-compiler/src/main/scala/scalanative/compiler/NIRCompiler.scala
+++ b/testing-compiler/src/main/scala/scalanative/compiler/NIRCompiler.scala
@@@ -1,0 -1,117 +1,117 @@@
+ package scala.scalanative
+ 
+ import scala.reflect.internal.util.{BatchSourceFile, NoFile, SourceFile}
+ import scala.reflect.internal.util.Position
+ 
+ import scala.tools.cmd.CommandLineParser
+ import scala.tools.nsc.{CompilerCommand, Global, Settings}
+ import scala.tools.nsc.io.{AbstractFile, VirtualDirectory}
+ import scala.tools.nsc.reporters.AbstractReporter
+ 
+ import java.nio.file.Files
+ import java.io.File
+ 
+ /**
+  * Helper class to compile snippets of code.
+  */
+ class NIRCompiler(outputDir: File) extends api.NIRCompiler {
+ 
+   def this() = this(Files.createTempDirectory("scala-native-target").toFile())
+ 
+   override def compile(code: String): Array[File] = {
+     val source = new BatchSourceFile(NoFile, code)
+     compile(Seq(source)).toArray
+   }
+ 
+   override def compile(base: File): Array[File] = {
+     val sources = getFiles(base, _.getName endsWith ".scala")
+     val sourceFiles = sources map { s =>
+       val abstractFile = AbstractFile.getFile(s)
+       new BatchSourceFile(abstractFile)
+     }
+     compile(sourceFiles).toArray
+   }
+ 
+   private def compile(sources: Seq[SourceFile]): Seq[File] = {
+     val global = getCompiler(options = ScalaNative)
+     import global._
+     val run = new Run
+     run.compileSources(sources.toList)
+     getFiles(outputDir, _ => true)
+   }
+ 
+   /**
+    * List of the files contained in `base` that sastisfy `filter`
+    */
+   private def getFiles(base: File, filter: File => Boolean): Seq[File] =
+     (if (filter(base)) Seq(base) else Seq()) ++
+       (Option(base.listFiles()) getOrElse Array.empty flatMap (getFiles(
+         _,
+         filter)))
+ 
+   private def reportError(error: String) =
+     throw new api.CompilationFailedException(error)
+ 
+   /**
+    * Reporter that ignores INFOs and WARNINGs, but directly aborts the compilation
+    * on ERRORs.
+    */
+   private class TestReporter(override val settings: Settings)
+       extends AbstractReporter {
+     override def display(pos: Position,
+                          msg: String,
+                          severity: Severity): Unit = severity match {
+       case INFO | WARNING => ()
 -      case ERROR          => reportError(msg)
++      case ERROR          => reportError(msg + pos.toString)
+     }
+ 
+     override def displayPrompt(): Unit = ()
+   }
+ 
+   /**
+    * Represents a basic compiler option (the string given to the command line invocation
+    * of scalac)
+    */
+   private implicit class CompilerOption(s: String) {
+     override def toString: String = s
+   }
+ 
+   /**
+    * An option to add a compiler plugin
+    */
+   private class CompilerPlugin(val jarPath: String,
+                                val classpath: List[String])
+       extends CompilerOption(
+         s"-Xplugin:$jarPath" + (if (classpath.nonEmpty)
+                                   classpath.mkString(" -cp ", ":", "")
+                                 else ""))
+ 
+   /**
+    * Option to add the scala-native compiler plugin
+    */
+   private case object ScalaNative
+       extends CompilerPlugin(jarPath = sys props "scalanative.nscplugin.jar",
+                              classpath =
+                                List(sys props "scalanative.testingcompiler.cp",
+                                     sys props "scalanative.nscplugin.jar"))
+ 
+   /**
+    * Returns an instance of `Global` configured according to the given options.
+    */
+   private def getCompiler(options: CompilerOption*): Global = {
+     // I don't really know how I can reset the compiler after a run, nor what else
+     // should also be reset, so for now this method creates new instances of everything,
+     // which is not so cool.
+     //
+     // Also, using `command.settings.outputDirs.setSingleOutput` I get strange classpath problems.
+     // What's even stranger, is that everything works fine using `-d`!
+     val outPath = outputDir.getAbsolutePath
+     val arguments =
+       CommandLineParser.tokenize(s"-d $outPath " + (options mkString " "))
+     val command  = new CompilerCommand(arguments.toList, reportError _)
+     val reporter = new TestReporter(command.settings)
+ 
+     new Global(command.settings, reporter)
+   }
+ 
+ }
diff --cc tools/src/main/scala/scala/scalanative/optimizer/analysis/ClassHierarchy.scala
index b726f70,b067552..b7f2bc6
--- a/tools/src/main/scala/scala/scalanative/optimizer/analysis/ClassHierarchy.scala
+++ b/tools/src/main/scala/scala/scalanative/optimizer/analysis/ClassHierarchy.scala
@@@ -55,6 -55,6 +55,8 @@@ object ClassHierarchy 
                      val traitNames: Seq[Global],
                      val isModule: Boolean)
        extends Scope {
++    override def toString(): String =
++      s"class $name"
      var range: Range           = _
      var parent: Option[Class]  = None
      var subclasses: Seq[Class] = Seq()
@@@ -151,6 -151,6 +153,8 @@@
                       val ty: nir.Type,
                       val isConcrete: Boolean)
        extends Node {
++        override def toString(): String =
++          s"method $name"
      var overrides: Seq[Method] = Seq()
      var overriden: Seq[Method] = Seq()
  
diff --cc tools/src/main/scala/scala/scalanative/optimizer/pass/InlineCaching.scala
index 6b04017,0000000..3ee22eb
mode 100644,000000..100644
--- a/tools/src/main/scala/scala/scalanative/optimizer/pass/InlineCaching.scala
+++ b/tools/src/main/scala/scala/scalanative/optimizer/pass/InlineCaching.scala
@@@ -1,313 -1,0 +1,312 @@@
 +package scala.scalanative
 +package optimizer
 +package pass
 +
 +import scala.io.Source
 +
 +import analysis.ClassHierarchy._
 +import analysis.ClassHierarchyExtractors._
 +import analysis.ControlFlow, ControlFlow.Block
 +import nir._, Inst.Let
 +import util.sh, Shows._
 +
 +/**
 + * Inline caching based on information gathered at runtime.
 + * Transforms polymorphic call sites to a sequence of type tests and static
 + * dispatches. Falls back to virtual dispatch if all type tests fail.
 + */
 +class InlineCaching(dispatchInfo: Map[String, Seq[Int]],
 +                    maxCandidates: Int)(implicit fresh: Fresh, top: Top)
 +    extends Pass {
 +  import InlineCaching._
 +
 +  /**
 +   * Finds the implementation of `meth` for an instance of `in`.
 +   *
 +   * @param meth The method we're looking for inside scope `in`.
 +   * @param in   The scope containing the method we're looking for.
 +   * @return The `Global` representing the concrete implementation of `meth`
 +   *         that should be used for `in`.
 +   */
-    private def findImpl(meth: Method, clss: Class): Option[Global] = {
-     lazy val allMethods =
-       clss.allmethods.filter(m => m.isConcrete && m.name.id == meth.name.id)
++  private def findImpl(meth: Method, in: Scope): Option[Global] = {
++    def inScope(in: Scope): Option[Global] =
++      in.methods collectFirst {
++        case m if m.isConcrete && m.name.id == meth.name.id => m.name
++      }
 +
-     // Is the method directly defined in the class we're interested in?
-     lazy val direct =
-       if (meth.in == clss) Some(clss.name member meth.name.id) else None
- 
-     // Is there a matching method in the class we're interested in?
-     lazy val inClass = allMethods find (_.in == clss) map (_.name)
- 
-     // Did we find a single match in all the methods?
-     lazy val single = allMethods match {
-       case Seq(m) =>
-         m.in match {
-           case c: Class if c.isModule =>
-             val className = c.name.id.drop("module.".length)
-             Some(Global.Top(className) member m.name.id)
-           case other =>
-             Some(other.name member m.name.id)
-         }
-       case _ => None
-     }
++    lazy val parents =
++      in match {
++        case clss: Class =>
++          (clss.parentName.flatMap(top.classWithName) +:
++            clss.traitNames.reverse.map(top.traitWithName)).flatten
++
++        case trt: Trait =>
++          trt.traitNames.reverse.flatMap(top.traitWithName)
 +
-     // Lookup using the vtable
-     lazy val vtable = {
-       clss.vtable lift meth.vindex flatMap {
-         case v: Val.Global => Some(v.name)
-         case _             => None
++        case _ =>
++          Seq.empty
 +      }
-     }
 +
-     direct orElse inClass orElse single orElse vtable
++    lazy val direct =
++      (in +: parents).flatMap(inScope).headOption
++
++    lazy val inParent =
++      parents.flatMap(findImpl(meth, _)).headOption
++
++    direct orElse inParent
 +  }
 +
 +  /**
 +   * Split the block `block` at the first sequence of instructions for which
 +   * `test` is true.
 +   * The instructions are grouped using `select` and then each group is given to
 +   * `test`.
 +   *
 +   * @param test      The test to select where to split the block.
 +   * @param select    How to group all the instructions in the block (eg. use a
 +   *                  sliding window of length 2)
 +   * @param makeParam A function that generates parameters for the block coming
 +   *                  after the split from the instructions where we split.
 +   * @param block     The block to split.
 +   */
 +  private def splitAt[T <: Inst](test: Seq[Inst] => Boolean)(
 +      select: Seq[Inst] => Seq[Seq[Inst]])(
 +      makeParams: Seq[T] => Seq[Val.Local])(
 +      block: Block): Option[(Block, Seq[Inst], Block)] = {
 +    val slices = select(block.insts)
 +    slices span (!test(_)) match {
 +      case (_, Seq()) =>
 +        None
 +      case (before, (insts: Seq[T]) +: after) =>
 +        val merge = fresh()
 +        val b0    = block.copy(insts = before.map(_.head))
 +        val b1 =
 +          Block(merge,
 +                makeParams(insts),
 +                after.tail.map(_.head) ++ after.last.tail)
 +
 +        Some((b0, insts, b1))
 +    }
 +  }
 +
 +  /**
 +   * Connect the sequence of blocks `blocks` up to `last`.
 +   *
 +   * @param blocks The blocks to connect, in this order
 +   * @param last   The last block in the chain.
 +   * @return A sequence of blocks such that they are all connected using the
 +   *         next block's name.
 +   */
 +  private def linkBlocks(blocks: Seq[Local => Block])(
 +      last: Block): Seq[Block] =
 +    (blocks foldRight List(last)) {
 +      case (blk, acc) => blk(acc.head.name) :: acc
 +    }
 +
 +  /**
 +   * Determines if `insts` is a virtual dispatch.
 +   *
 +   * @param inst The instructions to tests
 +   * @return true if `inst` is a virtual dispatch, false otherwise.
 +   */
 +  private def isVirtualDispatch(insts: Seq[Inst]): Boolean = insts match {
 +    case Seq(Let(n, Op.Method(_, MethodRef(_: Class, meth))),
 +             Let(_, Op.Call(_, Val.Local(ptr, _), _)))
 +        if meth.isVirtual && ptr == n =>
 +      true
 +    case _ =>
 +      false
 +  }
 +
 +  /**
 +   * Creates a single val from the last instruction in `lets`. Useful to create
 +   * the parameters of a new block when splitting blocks.
 +   *
 +   * @param lets The instructions whose value we want to pass
 +   * @return A single `Val.Local` whose name and type are the same as the last
 +   *         instruction in `lets`.
 +   */
 +  private def reuseLast(lets: Seq[Let]): Seq[Val.Local] =
 +    Seq(Val.Local(lets.last.name, lets.last.op.resty))
 +
 +  /**
 +   * Convert a block to the corresponding sequence of instruction
 +   *
 +   * @param block The block to convert
 +   * @return The sequence of instruction that corresponds to the same implicit
 +   *         block.
 +   */
 +  private def blockToInsts(block: Block): Seq[Inst] =
 +    block.label +: block.insts
 +
 +  /**
 +   * Generates the block that retrieves statically the address of the
 +   * implementation of `meth` for an instance of `clss`.
 +   *
 +   * @param meth The method to retrieve
 +   * @param call The original method call
 +   * @param clss The class for which we're looking for an implementation
 +   * @return A function that accepts a `Local` representing the name of the
 +   *         block to jump to after retrieving the address of the method.
 +   *         The destination block must accept one parameter of type `Ptr`,
 +   *         which is the address of the method.
 +   */
 +  private def makeStaticBlock(meth: Method,
 +                              call: Op.Call,
 +                              clss: Class): Local => Block =
 +    next => {
 +      val blockName = fresh()
-       val impl      = findImpl(meth, clss) getOrElse ???
++      val impl      = findImpl(meth, clss) getOrElse (throw new Exception("Not found: " + meth.id + " in " + clss.id))
 +      val result    = fresh()
 +
 +      Block(
 +        blockName,
 +        Nil,
 +        Seq(
 +          Let(result, call.copy(ptr = Val.Global(impl, Type.Ptr))),
 +          Inst.Jump(Next.Label(next, Seq(Val.Local(result, call.resty))))
 +        )
 +      )
 +    }
 +
 +  /**
 +   * Generates a type comparison.
 +   *
 +   * @param actualType         The type that we're observing at runtime
 +   * @param desiredType        The type we compare against.
 +   * @param correspondingBlock The block to jump to if the two types are equal.
 +   * @return A function that accepts a `Local` representing the name of the
 +   *         block to jump to if the two types are different.
 +   */
 +  private def makeTypeComparison(actualType: Val,
 +                                 desiredType: Val,
 +                                 correspondingBlock: Local): Local => Block = {
 +    val comparison = Val.Local(fresh(), Type.Bool)
 +
 +    (els: Local) =>
 +      Block(
 +        name = fresh(),
 +        params = Nil,
 +        insts = Seq(
 +          Let(comparison.name,
 +              Op.Comp(Comp.Ieq, Type.Ptr, actualType, desiredType)),
 +          Inst.If(comparison, Next(correspondingBlock), Next(els))
 +        )
 +      )
 +  }
 +
 +  /**
 +   * Adds inline caching to virtual calls in `block`.
 +   *
 +   * @param block The block on which to add inline caching.
 +   * @return A block that is semantically equivalent to `block`
 +   */
 +  private def addInlineCaching(enclosingDefn: Global)(block: Block): Seq[Block] =
 +    splitAt(isVirtualDispatch)(_.sliding(2).toSeq)(reuseLast)(block) match {
 +      case Some(
 +          (init,
 +           Seq(inst @ Let(n, Op.Method(obj, MethodRef(cls: Class, meth))),
 +               Let(_, call @ Op.Call(resty, ptr, args))),
 +           merge)) =>
 +        val reuse: Seq[Let] => Seq[Val.Local] = lets =>
 +          Seq(Val.Local(lets.last.name, lets.last.op.resty))
 +
 +        val key = {
 +          val enclosing = sh"$enclosingDefn".toString
 +          val instName  = sh"$n".toString
 +          val methName  = sh"${meth.name}".toString
 +          s"$enclosing -> $instName -> $methName"
 +        }
 +
 +        dispatchInfo getOrElse (key, Seq()) flatMap (top classWithId _) match {
 +          case allCandidates if allCandidates.nonEmpty =>
-             // We don't inline calls to all candidates, only the most frequent for
-             // performance.
-             val candidates = allCandidates take maxCandidates
- 
-             val typeptr = Val.Local(fresh(), Type.Ptr)
-             // Instructions to load the type id of `obj` at runtime.
-             // The result is in `typeid`.
-             val loadTypePtr: Seq[Let] = Seq(
-               Let(typeptr.name, Op.Load(Type.Ptr, obj))
-             )
- 
-             // The blocks that give the address for an inlined call
-             val staticBlocks: Seq[Block] =
-               candidates map (makeStaticBlock(meth, call, _)(merge.name))
- 
-             // The type comparisons. The argument is the block to go to if the
-             // type test fails.
-             val typeComparisons: Seq[Local => Block] =
-               staticBlocks zip candidates map {
-                 case (block, clss) =>
-                   makeTypeComparison(typeptr, clss.typeConst, block.name)
++            try {
++              // We don't inline calls to all candidates, only the most frequent for
++              // performance.
++              val candidates = allCandidates take maxCandidates
++
++              val typeptr = Val.Local(fresh(), Type.Ptr)
++              // Instructions to load the type id of `obj` at runtime.
++              // The result is in `typeid`.
++              val loadTypePtr: Seq[Let] = Seq(
++                Let(typeptr.name, Op.Load(Type.Ptr, obj))
++              )
++
++              // The blocks that give the address for an inlined call
++              val staticBlocks: Seq[Block] =
++                candidates map (makeStaticBlock(meth, call, _)(merge.name))
++
++              // The type comparisons. The argument is the block to go to if the
++              // type test fails.
++              val typeComparisons: Seq[Local => Block] =
++                staticBlocks zip candidates map {
++                  case (block, clss) =>
++                    makeTypeComparison(typeptr, clss.typeConst, block.name)
++                }
++
++              // If all type tests fail, we fallback to virtual dispatch.
++              val fallback: Block = {
++                val methptrptr = Val.Local(fresh(), Type.Ptr)
++                val methptr    = Val.Local(fresh(), Type.Ptr)
++                val newCall    = Let(call.copy(ptr = methptr))
++
++                Block(fresh(),
++                      Nil,
++                      Seq(
++                        Let(methptrptr.name,
++                            Op.Elem(cls.typeStruct,
++                                    typeptr,
++                                    Seq(Val.I32(0),
++                                        Val.I32(2), // index of vtable in type struct
++                                        Val.I32(meth.vindex)))),
++                        Let(methptr.name, Op.Load(Type.Ptr, methptrptr)),
++                        newCall,
++                        Inst.Jump(
++                          Next.Label(merge.name,
++                                     Seq(Val.Local(newCall.name, call.resty))))
++                      ))
 +              }
 +
-             // If all type tests fail, we fallback to virtual dispatch.
-             val fallback: Block = {
-               val methptrptr = Val.Local(fresh(), Type.Ptr)
-               val methptr    = Val.Local(fresh(), Type.Ptr)
-               val newCall    = Let(call.copy(ptr = methptr))
- 
-               Block(fresh(),
-                     Nil,
-                     Seq(
-                       Let(methptrptr.name,
-                           Op.Elem(cls.typeStruct,
-                                   typeptr,
-                                   Seq(Val.I32(0),
-                                       Val.I32(2), // index of vtable in type struct
-                                       Val.I32(meth.vindex)))),
-                       Let(methptr.name, Op.Load(Type.Ptr, methptrptr)),
-                       newCall,
-                       Inst.Jump(
-                         Next.Label(merge.name,
-                                    Seq(Val.Local(newCall.name, call.resty))))
-                     ))
++              // Execute start, load the typeid and jump to the first type test.
++              val start: Local => Block = typeComp =>
++                init.copy(
++                  insts = init.insts ++ loadTypePtr :+ Inst.Jump(Next(typeComp)))
++
++              linkBlocks(start +: typeComparisons)(fallback) ++
++                staticBlocks ++
++                addInlineCaching(enclosingDefn)(merge)
++            } catch {
++              case th: Throwable =>
++                println(th.getMessage)
++                Seq(block)
 +            }
 +
-             // Execute start, load the typeid and jump to the first type test.
-             val start: Local => Block = typeComp =>
-               init.copy(
-                 insts = init.insts ++ loadTypePtr :+ Inst.Jump(Next(typeComp)))
- 
-             linkBlocks(start +: typeComparisons)(fallback) ++
-               staticBlocks ++
-               addInlineCaching(enclosingDefn)(merge)
- 
 +          case _ =>
 +            Seq(block)
 +        }
 +      case _ =>
 +        Seq(block)
 +    }
 +
 +  override def preDefn = {
 +    case define: Defn.Define =>
 +      val graph          = ControlFlow.Graph(define.insts)
 +      val newBlocks      = graph.all.flatMap(addInlineCaching(define.name))
 +      Seq(define.copy(insts = newBlocks flatMap blockToInsts))
 +  }
 +
 +}
 +
 +object InlineCaching extends PassCompanion {
 +  override def apply(config: tools.Config, top: Top) =
 +    config.profileDispatchInfo match {
 +      case Some(info) if info.exists =>
 +        val maxCandidates = config.inlineCachingMaxCandidates
 +        val dispatchInfo =
 +          analysis.DispatchInfoParser(Source.fromFile(info).mkString)
 +        new InlineCaching(dispatchInfo, maxCandidates)(top.fresh, top)
 +
 +      case _ =>
 +        EmptyPass
 +    }
 +}
diff --cc tools/src/main/scala/scala/scalanative/optimizer/pass/LogInsts.scala
index 062eeff,0000000..92b60a2
mode 100644,000000..100644
--- a/tools/src/main/scala/scala/scalanative/optimizer/pass/LogInsts.scala
+++ b/tools/src/main/scala/scala/scalanative/optimizer/pass/LogInsts.scala
@@@ -1,99 -1,0 +1,126 @@@
 +package scala.scalanative
 +package optimizer
 +package pass
 +
 +import analysis.ClassHierarchy.Top
 +import tools.Config
 +import nir._
 +import Inst._
 +import Op._
 +
 +class LogInsts(implicit fresh: Fresh) extends Pass {
 +  import LogInsts._
 +
 +  private def call(ty: Type, v: Val.Global): Inst.Let =
 +    Let(Op.Call(ty, v, Seq()))
 +  override def preInst = {
 +    case inst: Inst.Let =>
 +      inst.op match {
 +        case c: Call =>
 +          Seq(call(log_callSig, log_call), inst)
 +
 +        case l: Load =>
 +          Seq(call(log_loadSig, log_load), inst)
 +
 +        case s: Store =>
 +          Seq(call(log_storeSig, log_store), inst)
 +
 +        case e: Elem =>
 +          Seq(call(log_elemSig, log_elem), inst)
 +
 +        case e: Extract =>
 +          Seq(call(log_extractSig, log_extract), inst)
 +
 +        case i: Insert =>
 +          Seq(call(log_insertSig, log_insert), inst)
 +
 +        case s: Stackalloc =>
 +          Seq(call(log_stackallocSig, log_stackalloc), inst)
 +
++        case b: Op.Bin =>
++          Seq(call(log_binSig, log_bin), inst)
++
++        case c: Op.Comp =>
++          Seq(call(log_compSig, log_comp), inst)
++
++        case c: Op.Conv =>
++          Seq(call(log_convSig, log_conv), inst)
++
 +        case s: Select =>
 +          Seq(call(log_selectSig, log_select), inst)
 +
 +        case _ =>
 +          Seq(inst)
 +      }
 +    case other =>
 +      Seq(other)
 +  }
 +}
 +
 +object LogInsts extends PassCompanion {
 +
 +  val log_callSig  = Type.Function(Seq(), Type.Void)
 +  val log_call     = Val.Global(Global.Top("log_call"), Type.Ptr)
 +  val log_callDecl = Defn.Declare(Attrs.None, log_call.name, log_callSig)
 +
 +  val log_loadSig  = Type.Function(Seq(), Type.Void)
 +  val log_load     = Val.Global(Global.Top("log_load"), Type.Ptr)
 +  val log_loadDecl = Defn.Declare(Attrs.None, log_load.name, log_loadSig)
 +
 +  val log_storeSig  = Type.Function(Seq(), Type.Void)
 +  val log_store     = Val.Global(Global.Top("log_store"), Type.Ptr)
 +  val log_storeDecl = Defn.Declare(Attrs.None, log_store.name, log_storeSig)
 +
 +  val log_elemSig  = Type.Function(Seq(), Type.Void)
 +  val log_elem     = Val.Global(Global.Top("log_elem"), Type.Ptr)
 +  val log_elemDecl = Defn.Declare(Attrs.None, log_elem.name, log_elemSig)
 +
 +  val log_extractSig = Type.Function(Seq(), Type.Void)
 +  val log_extract    = Val.Global(Global.Top("log_extract"), Type.Ptr)
 +  val log_extractDecl =
 +    Defn.Declare(Attrs.None, log_extract.name, log_extractSig)
 +
 +  val log_insertSig  = Type.Function(Seq(), Type.Void)
 +  val log_insert     = Val.Global(Global.Top("log_insert"), Type.Ptr)
 +  val log_insertDecl = Defn.Declare(Attrs.None, log_insert.name, log_insertSig)
 +
 +  val log_stackallocSig = Type.Function(Seq(), Type.Void)
 +  val log_stackalloc    = Val.Global(Global.Top("log_stackalloc"), Type.Ptr)
 +  val log_stackallocDecl =
 +    Defn.Declare(Attrs.None, log_stackalloc.name, log_stackallocSig)
 +
++  val log_binSig = Type.Function(Seq(), Type.Void)
++  val log_bin    = Val.Global(Global.Top("log_bin"), Type.Ptr)
++  val log_binDecl =
++    Defn.Declare(Attrs.None, log_bin.name, log_binSig)
++
++  val log_compSig = Type.Function(Seq(), Type.Void)
++  val log_comp    = Val.Global(Global.Top("log_comp"), Type.Ptr)
++  val log_compDecl =
++    Defn.Declare(Attrs.None, log_comp.name, log_compSig)
++
++  val log_convSig = Type.Function(Seq(), Type.Void)
++  val log_conv    = Val.Global(Global.Top("log_conv"), Type.Ptr)
++  val log_convDecl =
++    Defn.Declare(Attrs.None, log_conv.name, log_convSig)
++
 +  val log_selectSig  = Type.Function(Seq(), Type.Void)
 +  val log_select     = Val.Global(Global.Top("log_select"), Type.Ptr)
 +  val log_selectDecl = Defn.Declare(Attrs.None, log_select.name, log_selectSig)
 +
 +  override def injects: Seq[Defn] =
 +    Seq(log_callDecl,
 +        log_loadDecl,
 +        log_storeDecl,
 +        log_elemDecl,
 +        log_extractDecl,
 +        log_insertDecl,
 +        log_stackallocDecl,
++        log_binDecl,
++        log_compDecl,
++        log_convDecl,
 +        log_selectDecl)
 +
 +  override def apply(config: Config, top: Top): Pass =
 +    new LogInsts()(top.fresh)
 +}
diff --cc tools/src/test/scala/scala/scalanative/BenchmarkSpec.scala
index 0000000,79e3c22..b79c279
mode 000000,100644..100644
--- a/tools/src/test/scala/scala/scalanative/BenchmarkSpec.scala
+++ b/tools/src/test/scala/scala/scalanative/BenchmarkSpec.scala
@@@ -1,0 -1,75 +1,95 @@@
+ package scala.scalanative
+ 
+ import java.io.File
+ 
+ import optimizer.Driver
++import tools.Config
+ 
+ abstract class BenchmarkSpec extends BinarySpec {
+ 
 -  case class BenchmarkResult(minNs: Long, maxNs: Long, avgNs: Long) {
++  case class BenchmarkResult(minNs: Long, maxNs: Long, avgNs: Long, output: String) {
+     override def toString(): String = {
+       def toMs(ns: Long): Double = ns.toDouble / 1000.0
+       val format = new java.text.DecimalFormat("#.###")
+       val minMs = format.format(toMs(minNs))
+       val maxMs = format.format(toMs(maxNs))
+       val avgMs = format.format(toMs(avgNs))
 -      s"min = ${minMs}ms, max = ${maxMs}ms, avg = ${avgMs}ms"
++      "-" * 181 +
++        s"""min = ${minMs}ms, max = ${maxMs}ms, avg = ${avgMs}ms,
++           |output =
++           |$output
++           |""".stripMargin +
++           "-" * 181
+     }
+   }
+ 
 -  private def timed[T](op: => T): Long = {
++  private def timed[T](op: => T): (T, Long) = {
+     val startTime = System.nanoTime()
 -    val _         = op
 -    System.nanoTime - startTime
++    val result    = op
++    val totalTime = System.nanoTime - startTime
++    (result, totalTime)
+   }
+ 
+   private def run(iterations: Int, binary: File): BenchmarkResult = {
 -    var minNs     = Long.MaxValue
 -    var maxNs     = Long.MinValue
 -    val total = timed {
++    var minNs        = Long.MaxValue
++    var maxNs        = Long.MinValue
++    val (out, total) = timed {
++      val out = collection.mutable.Buffer.empty[String]
+       for { _ <- 1 to iterations } {
 -        val time = timed { run(binary) { case _ => () } }
 -        minNs = minNs min time
 -        maxNs = maxNs max time
++        val (outPart, time) = timed { run(binary) { case (_, out, _) => out.mkString("\n") } }
++        minNs               = minNs min time
++        maxNs               = maxNs max time
++        out += outPart
+       }
++      out.mkString("\n")
+     }
 -    BenchmarkResult(minNs, maxNs, total)
++    BenchmarkResult(minNs, maxNs, total, out)
+   }
+ 
+   private def makeMain(entry: String,
+                        iterations: Int): String = {
 -    val call = "A.main(args)\n" * iterations
++
++    val call = s"${entry.substring(0, entry.length - 1)}.main(args)\n" * iterations
+     s"""object Benchmark {
+        |  def main(args: Array[String]): Unit = {
+        |    $call
+        |  }
+        |}""".stripMargin
+   }
+ 
+   def benchmark[T](entry: String,
 -                   baseDriver: Driver,
 -                   improvedDriver: Driver,
++                   driver: Driver,
++                   configFn: Config => Config,
+                    iterations: Int,
+                    sources: Map[String, String],
+                    linkage: Map[String, String] = Map.empty,
 -                   opts: Seq[String] = defaultClangOptions)(fn: (BenchmarkResult, BenchmarkResult) => T): T = {
 -
++                   opts: Seq[String] = defaultClangOptions)(fn: BenchmarkResult => T): T = {
+     val newSources =
 -      sources + ("Benchmark.scala" -> makeMain(xentry, iterations))
++      sources + ("Benchmark.scala" -> makeMain(entry, iterations))
+     val newEntry =
+       "Benchmark$"
+ 
 -    val baseResult =
 -      makeBinary(newEntry, newSources, baseDriver, linkage, opts) {
 -        case (_, _, baseBinary) => run(iterations, baseBinary)
++    val result =
++      makeBinary(newEntry, newSources, driver, configFn, linkage, opts) {
++        case (_, _, binary) => run(1, binary)
+       }
+ 
 -    val improvedResult =
 -      makeBinary(newEntry, newSources, improvedDriver, linkage, opts) {
 -        case (_, _, improvedBinary) => run(iterations, improvedBinary)
++    fn(result)
++  }
++
++  def compare[T](entry: String,
++                 setups: Seq[(Driver, Config => Config)],
++                 iterations: Int,
++                 sources: Map[String, String],
++                 linkage: Map[String, String] = Map.empty,
++                 opts: Seq[String] = defaultClangOptions)(fn: Seq[BenchmarkResult] => T): T = {
++
++    val results =
++      setups map { case (driver, configFn) =>
++        benchmark(entry, driver, configFn, iterations, sources, linkage, opts)(identity)
+       }
+ 
 -    fn(baseResult, improvedResult)
++    fn(results)
+   }
+ 
+ }
diff --cc tools/src/test/scala/scala/scalanative/BinarySpec.scala
index 0000000,34f998a..02bcd76
mode 000000,100644..100644
--- a/tools/src/test/scala/scala/scalanative/BinarySpec.scala
+++ b/tools/src/test/scala/scala/scalanative/BinarySpec.scala
@@@ -1,0 -1,115 +1,117 @@@
+ package scala.scalanative
+ 
+ import llvm.LLVM
+ import java.io.File
+ import java.nio.file.Files.{createTempDirectory, createTempFile}
+ import scala.sys.process.{Process, ProcessLogger}
+ import tools.Config
+ import optimizer.Driver
+ import io.VirtualFile
+ 
+ /**
+  * Base class to test:
+  *  - Producing a binary file from scala code
+  *  - Running the binary file.
+  */
+ abstract class BinarySpec extends CodeGenSpec {
+ 
+   /** The default options to pass to clang */
+   val defaultClangOptions: Seq[String] = {
+     val lrt = Option(sys props "os.name") match {
+       case Some("Linux") => Seq("-lrt")
+       case _             => Seq()
+     }
+     LLVM.includes ++ LLVM.libs ++ lrt
+   }
+ 
+   /**
+    * Compiles the given sources and produce an executable binary file.
+    *
+    * @param entry   The entry point for the linker.
+    * @param sources Map from file name to file content representing all the code
+    *                to compile.
+    * @param driver  The driver that defines the pipeline.
+    * @param linkage Given a native library, provide the linkage kind (static or
+    *                dynamic). Defaults to dynamic.
+    * @param opts    The options to pass to clang.
+    * @param fn      A function to apply to the products of the compilation.
+    * @return The result of applying `fn` to the result of compilation.
+    */
+   def makeBinary[T](entry: String,
+                     sources: Map[String, String],
+                     driver: Driver = Driver(),
++                    configFn: Config => Config = identity,
+                     linkage: Map[String, String] = Map.empty,
+                     opts: Seq[String] = defaultClangOptions)(
+       fn: (Config, Seq[nir.Attr.Link], File) => T): T =
 -    codegen(entry, sources, driver) {
++    codegen(entry, sources, driver, configFn) {
+       case (config, links, llFile) =>
+         val clangpp   = LLVM.discover("clang++", Seq(("3", "8"), ("3", "7")))
+         val target    = createTempDirectory("native-test-target").toFile()
+         val nativelib = new File(sys.props("scalanative.nativelib.dir"))
+         val binary    = createTempFile("native-binary", null).toFile()
+         val logger    = ProcessLogger(_ => (), println _)
+         val appll     = write(llFile)
+ 
+         LLVM.compileLl(clangpp,
+                        target,
+                        nativelib,
+                        appll,
+                        binary,
+                        links.map(_.name),
+                        linkage,
+                        opts,
+                        logger)
+ 
+         fn(config, links, binary)
+     }
+ 
+   /**
+    * Compiles and runs the given sources.
+    *
+    * @param entry The entry point for the linker.
+    * @param sources Map from file name to file content representing all the code
+    *                to compile.
+    * @param driver  The driver that defines the pipeline.
+    * @param linkage Given a native library, provide the linkage kind (static or
+    *                dynamic). Defaults to dynamic.
+    * @param opts    The options to pass to clang.
+    * @param fn      A function to apply to the output of the run.
+    * @return The result of applying `fn` to the output of the run.
+    */
+   def run[T](entry: String,
+              sources: Map[String, String],
+              driver: Driver = Driver(),
++             configFn: Config => Config = identity,
+              linkage: Map[String, String] = Map.empty,
+              opts: Seq[String] = defaultClangOptions)(
+       fn: (Int, Seq[String], Seq[String]) => T): T =
 -    makeBinary(entry, sources, driver, linkage, opts) {
++    makeBinary(entry, sources, driver, configFn, linkage, opts) {
+       case (_, _, binary) => run(binary)(fn)
+     }
+ 
+   /**
+    * Runs the given binary file.
+    *
+    * @param binary The binary file to run.
+    * @param fn     A function to apply to the output of the run.
+    * @return The result of applying `fn` to the output of the run.
+    */
+   def run[T](binary: File)(fn: (Int, Seq[String], Seq[String]) => T): T = {
+     val outLines = scala.collection.mutable.Buffer.empty[String]
+     val errLines = scala.collection.mutable.Buffer.empty[String]
+     val logger   = ProcessLogger(outLines += _, errLines += _)
+     val exitCode = Process(binary.getAbsolutePath) ! logger
+ 
+     fn(exitCode, outLines, errLines)
+   }
+ 
+   private def write(virtual: VirtualFile): File = {
+     val out = createTempFile("native-codegen", ".ll").toFile()
+     val channel =
+       java.nio.channels.Channels.newChannel(new java.io.FileOutputStream(out))
+     channel.write(virtual.contents)
+     out
+   }
+ 
+ }
diff --cc tools/src/test/scala/scala/scalanative/CodeGenSpec.scala
index 0000000,dee4099..952e22e
mode 000000,100644..100644
--- a/tools/src/test/scala/scala/scalanative/CodeGenSpec.scala
+++ b/tools/src/test/scala/scala/scalanative/CodeGenSpec.scala
@@@ -1,0 -1,35 +1,36 @@@
+ package scala.scalanative
+ 
+ import io.VirtualFile
+ import optimizer.Driver
+ import java.nio.file.Paths
+ import tools.Config
+ 
+ /** Base class to test code generation */
+ abstract class CodeGenSpec extends OptimizerSpec {
+ 
+   /**
+    * Performs code generation on the given sources.
+    *
+    * @param entry   The entry point for the linker.
+    * @param sources Map from file name to file content representing all the code
+    *                to compile
+    * @param fn      A function to apply to the products of the compilation.
+    * @param driver  The driver that defines the pipeline.
+    * @return The result of applying `fn` to the resulting file.
+    */
+   def codegen[T](entry: String,
+                  sources: Map[String, String],
 -                 driver: Driver = Driver())(fn: (Config, Seq[nir.Attr.Link],
++                 driver: Driver = Driver(),
++                 configFn: Config => Config = identity)(fn: (Config, Seq[nir.Attr.Link],
+                                                  VirtualFile) => T): T =
 -    optimize(entry, sources, driver) {
++    optimize(entry, sources, driver, configFn) {
+       case (config, links, assembly) =>
+         tools.codegen(config, assembly)
+         val llFile =
+           config.targetDirectory.get(Paths.get("out.ll")) getOrElse fail(
+             "out.ll not found.")
+ 
+         fn(config, links, llFile)
+     }
+ 
+ }
diff --cc tools/src/test/scala/scala/scalanative/InlineCachingSpec.scala
index 0000000,0000000..ddc23b5
new file mode 100644
--- /dev/null
+++ b/tools/src/test/scala/scala/scalanative/InlineCachingSpec.scala
@@@ -1,0 -1,0 +1,64 @@@
++package scala.scalanative
++
++import java.io.File
++import java.nio.file.Files
++
++import optimizer.Driver
++import tools.Config
++
++abstract class InlineCachingSpec extends BenchmarkSpec {
++
++  def withInlineCaching[T](entry: String,
++                        driver: Driver,
++                        iterations: Int,
++                        configFn: Config => Config = identity,
++                        sources: Map[String, String],
++                        linkage: Map[String, String] = Map.empty,
++                        opts: Seq[String] = defaultClangOptions)(fn: BenchmarkResult => T): T = {
++    val configForProfiling =
++      (out: File) => configFn andThen (_.withProfileDispatch(true)
++                                        .withProfileDispatchInfo(Some(out)))
++
++    val configForBenchmarking =
++      (out: File) => configFn andThen (_.withProfileDispatchInfo(Some(out)))
++
++    val withProfilingConfigs = (configFn: Config => Config) => (cfg: Config) => configFn(cfg.withProfileDispatch(true))
++    val dispatchInfo = Files.createTempFile("dispatch", ".txt").toFile()
++
++    // Collect info
++    run(entry,
++        sources,
++        driver,
++        configForProfiling(dispatchInfo),
++        linkage,
++        opts)((_, _, _) => ())
++
++    assert(dispatchInfo.exists)
++
++    // Benchmark
++    benchmark(entry,
++              driver,
++              configForBenchmarking(dispatchInfo),
++              iterations,
++              sources,
++              linkage,
++              opts)(fn)
++
++  }
++
++  def withoutAndWith[T](entry: String,
++                 driver: Driver,
++                 iterations: Int,
++                 sources: Map[String, String],
++                 configFn: Config => Config = identity,
++                 linkage: Map[String, String] = Map.empty,
++                 opts: Seq[String] = defaultClangOptions)(fn: (BenchmarkResult, BenchmarkResult) => T): T = {
++    val baseResult =
++      benchmark(entry, driver, configFn, iterations, sources, linkage, opts)(identity)
++
++    val inlineCachingResult =
++      withInlineCaching(entry, driver, iterations, configFn, sources, linkage, opts)(identity)
++
++    fn(baseResult, inlineCachingResult)
++  }
++}
diff --cc tools/src/test/scala/scala/scalanative/LinkerSpec.scala
index 0000000,edd9804..893b586
mode 000000,100644..100644
--- a/tools/src/test/scala/scala/scalanative/LinkerSpec.scala
+++ b/tools/src/test/scala/scala/scalanative/LinkerSpec.scala
@@@ -1,0 -1,71 +1,72 @@@
+ package scala.scalanative
+ 
+ import scala.language.implicitConversions
+ 
+ import java.io.File
+ import java.nio.file.Files
+ 
+ import util.Scope
+ import io.VirtualDirectory
+ import nir.Global
+ import tools.Config
+ import linker.Path
+ import optimizer.Driver
+ 
+ import org.scalatest.FlatSpec
+ 
+ /** Base class to test the linker. */
+ abstract class LinkerSpec extends FlatSpec {
+ 
+   /**
+    * Runs the linker using `driver` with `entry` as entry point on `sources`,
+    * and applies `fn` to the definitions.
+    *
+    * @param entry   The entry point for the linker.
+    * @param sources Map from file name to file content representing all the code
+    *                to compile and link.
+    * @param driver  The driver that defines the pipeline.
+    * @param fn      A function to apply to the products of the compilation.
+    * @return The result of applying `fn` to the resulting definitions.
+    */
+   def link[T](entry: String,
+               sources: Map[String, String],
 -              driver: Driver = Driver())(fn: (Config, Seq[nir.Attr.Link],
++              driver: Driver = Driver(),
++              configFn: Config => Config = identity)(fn: (Config, Seq[nir.Attr.Link],
+                                               Seq[nir.Defn]) => T): T =
+     Scope { implicit in =>
+       val outDir     = Files.createTempDirectory("native-test-out").toFile()
+       val compiler   = NIRCompiler.getCompiler(outDir)
+       val sourcesDir = NIRCompiler.writeSources(sources)
+       val files      = compiler.compile(sourcesDir)
 -      val config     = makeConfig(outDir, entry)
++      val config     = configFn(makeConfig(outDir, entry))
+ 
+       val (_, links, defns) = tools.link(config, driver)
+ 
+       fn(config, links, defns)
+     }
+ 
+   private def makePaths(outDir: File)(implicit in: Scope) = {
+     val parts: Array[File] =
+       sys
+         .props("scalanative.nativeruntime.cp")
+         .split(File.pathSeparator)
+         .map(new File(_))
+ 
+     (parts :+ outDir).map(p => Path(VirtualDirectory.real(p)))
+   }
+ 
+   private def makeConfig(outDir: File, entryName: String)(
+       implicit in: Scope): Config = {
+     val entry = Global.Top(entryName)
+     val paths = makePaths(outDir)
+     Config.empty
+       .withTargetDirectory(VirtualDirectory.real(outDir))
+       .withPaths(paths)
+       .withEntry(entry)
+   }
+ 
+   protected implicit def String2MapStringString(
+       code: String): Map[String, String] =
+     Map("source.scala" -> code)
+ 
+ }
diff --cc tools/src/test/scala/scala/scalanative/OptimizerSpec.scala
index 0000000,5a40397..bfc5bb7
mode 000000,100644..100644
--- a/tools/src/test/scala/scala/scalanative/OptimizerSpec.scala
+++ b/tools/src/test/scala/scala/scalanative/OptimizerSpec.scala
@@@ -1,0 -1,29 +1,30 @@@
+ package scala.scalanative
+ 
+ import optimizer.Driver
+ import tools.Config
+ 
+ /** Base class to test the optimizer */
+ abstract class OptimizerSpec extends LinkerSpec {
+ 
+   /**
+    * Runs the optimizer defined by `driver` on `sources`.
+    * The code will first be linked using `entry` as entry point.
+    *
+    * @param entry   The entry point for the linker.
+    * @param sources Map from file name to file content representing all the code
+    *                to compile and optimize.
+    * @param driver  The driver that defines the pipeline.
+    * @param fn      A function to apply to the products of the compilation.
+    * @return The result of applying `fn` to the resulting definitions.
+    */
+   def optimize[T](entry: String,
+                   sources: Map[String, String],
 -                  driver: Driver = Driver())(fn: (Config, Seq[nir.Attr.Link],
++                  driver: Driver = Driver(),
++                  configFn: Config => Config = identity)(fn: (Config, Seq[nir.Attr.Link],
+                                                   Seq[nir.Defn]) => T): T =
 -    link(entry, sources, driver) {
++    link(entry, sources, driver, configFn) {
+       case (config, links, assembly) =>
+         fn(config, links, tools.optimize(config, driver, assembly))
+     }
+ 
+ }
diff --cc tools/src/test/scala/scala/scalanative/optimizer/pass/GlobalBoxingEliminationBenchmark.scala
index 0000000,35e5e3d..52e2d70
mode 000000,100644..100644
--- a/tools/src/test/scala/scala/scalanative/optimizer/pass/GlobalBoxingEliminationBenchmark.scala
+++ b/tools/src/test/scala/scala/scalanative/optimizer/pass/GlobalBoxingEliminationBenchmark.scala
@@@ -1,0 -1,25 +1,24 @@@
+ package scala.scalanative
+ package optimizer
+ package pass
+ 
+ import org.scalatest._
+ 
+ class CopyPropagationBenchmark extends BenchmarkSpec with Matchers {
+ 
+   "Copy propagation" should "not degrade performance" in {
+     val baseDriver     = Driver().remove(GlobalBoxingElimination)
+     val improvedDriver = Driver()
+ 
 -    benchmark("A$",
 -              baseDriver,
 -              improvedDriver,
 -              20,
 -              """object A {
 -                |  def main(args: Array[String]): Unit =
 -                |    println("Hello, world!")
 -                |}""".stripMargin) {
 -      case (base, improved) =>
++    compare("A$",
++            Seq((baseDriver, identity), (improvedDriver, identity)),
++            20,
++            """object A {
++              |  def main(args: Array[String]): Unit =
++              |    println("Hello, world!")
++              |}""".stripMargin) {
++      case Seq(base, improved) =>
+         improved.avgNs should be < base.avgNs
+     }
+   }
+ }
diff --cc tools/src/test/scala/scala/scalanative/optimizer/pass/InlineCachingBenchmark.scala
index 0000000,0000000..e3d4cea
new file mode 100644
--- /dev/null
+++ b/tools/src/test/scala/scala/scalanative/optimizer/pass/InlineCachingBenchmark.scala
@@@ -1,0 -1,0 +1,731 @@@
++package scala.scalanative
++package optimizer
++package pass
++
++class InlineCachingBenchmark extends InlineCachingSpec {
++  "Inline caching" should "improve performance in DeltaBlue" in {
++    val sources =
++      """/*                     __                                               *\
++        |**     ________ ___   / /  ___      __ ____  Scala.js Benchmarks        **
++        |**    / __/ __// _ | / /  / _ | __ / // __/  (c) 2013, Jonas Fonseca    **
++        |**  __\ \/ /__/ __ |/ /__/ __ |/_// /_\ \                               **
++        |** /____/\___/_/ |_/____/_/ | |__/ /____/                               **
++        |**                          |/____/                                     **
++        |\*                                                                      */
++        |
++        |// Copyright 2011 Google Inc. All Rights Reserved.
++        |// Copyright 1996 John Maloney and Mario Wolczko
++        |//
++        |// This file is part of GNU Smalltalk.
++        |//
++        |// GNU Smalltalk is free software; you can redistribute it and/or modify it
++        |// under the terms of the GNU General Public License as published by the Free
++        |// Software Foundation; either version 2, or (at your option) any later version.
++        |//
++        |// GNU Smalltalk is distributed in the hope that it will be useful, but WITHOUT
++        |// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
++        |// FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more
++        |// details.
++        |//
++        |// You should have received a copy of the GNU General Public License along with
++        |// GNU Smalltalk; see the file COPYING.  If not, write to the Free Software
++        |// Foundation, 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
++        |//
++        |// Translated first from Smalltalk to JavaScript, and finally to
++        |// Dart by Google 2008-2010.
++        |// Translated to Scala.js by Jonas Fonseca 2013
++        |
++        |package deltablue
++        |
++        |/**
++        | * A Scala implementation of the DeltaBlue constraint-solving
++        | * algorithm, as described in:
++        | *
++        | * "The DeltaBlue Algorithm: An Incremental Constraint Hierarchy Solver"
++        | *   Bjorn N. Freeman-Benson and John Maloney
++        | *   January 1990 Communications of the ACM,
++        | *   also available as University of Washington TR 89-08-06.
++        | *
++        | * Beware: this benchmark is written in a grotesque style where
++        | * the constraint model is built by side-effects from constructors.
++        | * I've kept it this way to avoid deviating too much from the original
++        | * implementation.
++        | */
++        |import scala.collection.mutable.{ArrayBuffer, ListBuffer, Stack}
++        |
++        |object DeltaBlue {
++        |
++        |  def main(args: Array[String]): Unit = {
++        |    chainTest(100)
++        |    projectionTest(100)
++        |  }
++        |  /**
++        |   * This is the standard DeltaBlue benchmark. A long chain of equality
++        |   * constraints is constructed with a stay constraint on one end. An
++        |   * edit constraint is then added to the opposite end and the time is
++        |   * measured for adding and removing this constraint, and extracting
++        |   * and executing a constraint satisfaction plan. There are two cases.
++        |   * In case 1, the added constraint is stronger than the stay
++        |   * constraint and values must propagate down the entire length of the
++        |   * chain. In case 2, the added constraint is weaker than the stay
++        |   * constraint so it cannot be accomodated. The cost in this case is,
++        |   * of course, very low. Typical situations lie somewhere between these
++        |   * two extremes.
++        |   */
++        |  def chainTest(n: Int) {
++        |    implicit val planner = new Planner()
++        |    var prev: Variable   = null
++        |    var first: Variable  = null
++        |    var last: Variable   = null
++        |
++        |    // Build chain of n equality constraints.
++        |    for (i <- 0 to n) {
++        |      val v = new Variable("v", 0)
++        |      if (prev != null) new EqualityConstraint(prev, v, REQUIRED)
++        |      if (i == 0) first = v
++        |      if (i == n) last = v
++        |      prev = v
++        |    }
++        |    new StayConstraint(last, STRONG_DEFAULT)
++        |    val edit = new EditConstraint(first, PREFERRED)
++        |    val plan = planner.extractPlanFromConstraints(Seq(edit))
++        |    for (i <- 0 until 100) {
++        |      first.value = i
++        |      plan.execute()
++        |      if (last.value != i) {
++        |        print("Chain test failed.\n{last.value)\n{i}")
++        |      }
++        |    }
++        |  }
++        |
++        |  /**
++        |   * This test constructs a two sets of variables related to each
++        |   * other by a simple linear transformation (scale and offset). The
++        |   * time is measured to change a variable on either side of the
++        |   * mapping and to change the scale and offset factors.
++        |   */
++        |  def projectionTest(n: Int) {
++        |    implicit val planner = new Planner()
++        |    val scale            = new Variable("scale", 10)
++        |    val offset           = new Variable("offset", 1000)
++        |    var src: Variable    = null
++        |    var dst: Variable    = null
++        |
++        |    val dests = new ArrayBuffer[Variable](n)
++        |    for (i <- 0 until n) {
++        |      src = new Variable("src", i)
++        |      dst = new Variable("dst", i)
++        |      dests += dst
++        |      new StayConstraint(src, NORMAL)
++        |      new ScaleConstraint(src, scale, offset, dst, REQUIRED)
++        |    }
++        |    change(src, 17)
++        |    if (dst.value != 1170) print("Projection 1 failed")
++        |    change(dst, 1050)
++        |    if (src.value != 5) print("Projection 2 failed")
++        |    change(scale, 5)
++        |    for (i <- 0 until n - 1) {
++        |      if (dests(i).value != i * 5 + 1000) print("Projection 3 failed")
++        |    }
++        |    change(offset, 2000)
++        |    for (i <- 0 until n - 1) {
++        |      if (dests(i).value != i * 5 + 2000) print("Projection 4 failed")
++        |    }
++        |  }
++        |
++        |  def change(v: Variable, newValue: Int)(implicit planner: Planner) {
++        |    val edit = new EditConstraint(v, PREFERRED)
++        |    val plan = planner.extractPlanFromConstraints(Seq(edit))
++        |    for (i <- 0 until 10) {
++        |      v.value = newValue
++        |      plan.execute()
++        |    }
++        |    edit.destroyConstraint
++        |  }
++        |}
++        |
++        |/**
++        | * Strengths are used to measure the relative importance of constraints.
++        | * New strengths may be inserted in the strength hierarchy without
++        | * disrupting current constraints.  Strengths cannot be created outside
++        | * this class, so == can be used for value comparison.
++        | */
++        |sealed class Strength(val value: Int, val name: String) {
++        |  def nextWeaker = value match {
++        |    case 0 => STRONG_PREFERRED
++        |    case 1 => PREFERRED
++        |    case 2 => STRONG_DEFAULT
++        |    case 3 => NORMAL
++        |    case 4 => WEAK_DEFAULT
++        |    case 5 => WEAKEST
++        |  }
++        |}
++        |
++        |case object REQUIRED         extends Strength(0, "required")
++        |case object STRONG_PREFERRED extends Strength(1, "strongPreferred")
++        |case object PREFERRED        extends Strength(2, "preferred")
++        |case object STRONG_DEFAULT   extends Strength(3, "strongDefault")
++        |case object NORMAL           extends Strength(4, "normal")
++        |case object WEAK_DEFAULT     extends Strength(5, "weakDefault")
++        |case object WEAKEST          extends Strength(6, "weakest")
++        |
++        |// Compile time computed constants.
++        |object Strength {
++        |
++        |  def stronger(s1: Strength, s2: Strength): Boolean =
++        |    s1.value < s2.value
++        |
++        |  def weaker(s1: Strength, s2: Strength): Boolean =
++        |    s1.value > s2.value
++        |
++        |  def weakest(s1: Strength, s2: Strength) =
++        |    if (weaker(s1, s2)) s1 else s2
++        |
++        |  def strongest(s1: Strength, s2: Strength) =
++        |    if (stronger(s1, s2)) s1 else s2
++        |}
++        |
++        |abstract class Constraint(val strength: Strength)(implicit planner: Planner) {
++        |
++        |  def isSatisfied(): Boolean
++        |  def markUnsatisfied(): Unit
++        |  def addToGraph(): Unit
++        |  def removeFromGraph(): Unit
++        |  def chooseMethod(mark: Int): Unit
++        |  def markInputs(mark: Int): Unit
++        |  def inputsKnown(mark: Int): Boolean
++        |  def output(): Variable
++        |  def execute(): Unit
++        |  def recalculate(): Unit
++        |
++        |  /// Activate this constraint and attempt to satisfy it.
++        |  def addConstraint() {
++        |    addToGraph()
++        |    planner.incrementalAdd(this)
++        |  }
++        |
++        |  /**
++        |   * Attempt to find a way to enforce this constraint. If successful,
++        |   * record the solution, perhaps modifying the current dataflow
++        |   * graph. Answer the constraint that this constraint overrides, if
++        |   * there is one, or nil, if there isn't.
++        |   * Assume: I am not already satisfied.
++        |   */
++        |  def satisfy(mark: Int): Constraint = {
++        |    chooseMethod(mark)
++        |    if (!isSatisfied()) {
++        |      if (strength == REQUIRED) {
++        |        print("Could not satisfy a required constraint!")
++        |      }
++        |      null
++        |    } else {
++        |      markInputs(mark)
++        |      val out        = output()
++        |      val overridden = out.determinedBy
++        |      if (overridden != null)
++        |        overridden.markUnsatisfied()
++        |      out.determinedBy = this
++        |      if (!planner.addPropagate(this, mark))
++        |        print("Cycle encountered")
++        |      out.mark = mark
++        |      overridden
++        |    }
++        |  }
++        |
++        |  def destroyConstraint {
++        |    if (isSatisfied())
++        |      planner.incrementalRemove(this)
++        |    removeFromGraph()
++        |  }
++        |
++        |  /**
++        |   * Normal constraints are not input constraints.  An input constraint
++        |   * is one that depends on external state, such as the mouse, the
++        |   * keybord, a clock, or some arbitraty piece of imperative code.
++        |   */
++        |  def isInput = false
++        |}
++        |
++        |/**
++        | * Abstract superclass for constraints having a single possible output variable.
++        | */
++        |abstract class UnaryConstraint(myOutput: Variable, strength: Strength)(
++        |    implicit planner: Planner)
++        |    extends Constraint(strength) {
++        |
++        |  private var satisfied = false
++        |
++        |  addConstraint()
++        |
++        |  /// Adds this constraint to the constraint graph
++        |  def addToGraph() {
++        |    myOutput.addConstraint(this)
++        |    satisfied = false
++        |  }
++        |
++        |  /// Decides if this constraint can be satisfied and records that decision.
++        |  def chooseMethod(mark: Int) {
++        |    satisfied = (myOutput.mark != mark) &&
++        |        Strength.stronger(strength, myOutput.walkStrength)
++        |  }
++        |
++        |  /// Returns true if this constraint is satisfied in the current solution.
++        |  def isSatisfied() = satisfied
++        |
++        |  def markInputs(mark: Int) {
++        |    // has no inputs.
++        |  }
++        |
++        |  /// Returns the current output variable.
++        |  def output() = myOutput
++        |
++        |  /**
++        |   * Calculate the walkabout strength, the stay flag, and, if it is
++        |   * 'stay', the value for the current output of this constraint. Assume
++        |   * this constraint is satisfied.
++        |   */
++        |  def recalculate() {
++        |    myOutput.walkStrength = strength
++        |    myOutput.stay = !isInput
++        |    if (myOutput.stay) execute(); // Stay optimization.
++        |  }
++        |
++        |  /// Records that this constraint is unsatisfied.
++        |  def markUnsatisfied() {
++        |    satisfied = false
++        |  }
++        |
++        |  def inputsKnown(mark: Int) = true
++        |
++        |  def removeFromGraph() {
++        |    if (myOutput != null) myOutput.removeConstraint(this)
++        |    satisfied = false
++        |  }
++        |}
++        |
++        |/**
++        | * Variables that should, with some level of preference, stay the same.
++        | * Planners may exploit the fact that instances, if satisfied, will not
++        | * change their output during plan execution.  This is called "stay
++        | * optimization".
++        | */
++        |class StayConstraint(v: Variable, str: Strength)(implicit planner: Planner)
++        |    extends UnaryConstraint(v, str) {
++        |  def execute() {
++        |    // Stay constraints do nothing.
++        |  }
++        |}
++        |
++        |/**
++        | * A unary input constraint used to mark a variable that the client
++        | * wishes to change.
++        | */
++        |class EditConstraint(v: Variable, str: Strength)(implicit planner: Planner)
++        |    extends UnaryConstraint(v, str) {
++        |
++        |  /// Edits indicate that a variable is to be changed by imperative code.
++        |  override val isInput = true
++        |
++        |  def execute() {
++        |    // Edit constraints do nothing.
++        |  }
++        |}
++        |
++        |object Direction {
++        |  final val NONE     = 1
++        |  final val FORWARD  = 2
++        |  final val BACKWARD = 0
++        |}
++        |
++        |/**
++        | * Abstract superclass for constraints having two possible output
++        | * variables.
++        | */
++        |abstract class BinaryConstraint(v1: Variable,
++        |                                v2: Variable,
++        |                                strength: Strength)(implicit planner: Planner)
++        |    extends Constraint(strength) {
++        |
++        |  protected var direction = Direction.NONE
++        |
++        |  addConstraint()
++        |
++        |  /**
++        |   * Decides if this constraint can be satisfied and which way it
++        |   * should flow based on the relative strength of the variables related,
++        |   * and record that decision.
++        |   */
++        |  def chooseMethod(mark: Int) {
++        |    if (v1.mark == mark) {
++        |      direction =
++        |        if ((v2.mark != mark && Strength.stronger(strength, v2.walkStrength)))
++        |          Direction.FORWARD
++        |        else
++        |          Direction.NONE
++        |    }
++        |    if (v2.mark == mark) {
++        |      direction =
++        |        if (v1.mark != mark && Strength.stronger(strength, v1.walkStrength))
++        |          Direction.BACKWARD
++        |        else
++        |          Direction.NONE
++        |    }
++        |    if (Strength.weaker(v1.walkStrength, v2.walkStrength)) {
++        |      direction =
++        |        if (Strength.stronger(strength, v1.walkStrength))
++        |          Direction.BACKWARD
++        |        else
++        |          Direction.NONE
++        |    } else {
++        |      direction =
++        |        if (Strength.stronger(strength, v2.walkStrength))
++        |          Direction.FORWARD
++        |        else
++        |          Direction.BACKWARD
++        |    }
++        |  }
++        |
++        |  /// Add this constraint to the constraint graph.
++        |  override def addToGraph() {
++        |    v1.addConstraint(this)
++        |    v2.addConstraint(this)
++        |    direction = Direction.NONE
++        |  }
++        |
++        |  /// Answer true if this constraint is satisfied in the current solution.
++        |  def isSatisfied() = direction != Direction.NONE
++        |
++        |  /// Mark the input variable with the given mark.
++        |  def markInputs(mark: Int) {
++        |    input().mark = mark
++        |  }
++        |
++        |  /// Returns the current input variable
++        |  def input() = if (direction == Direction.FORWARD) v1 else v2
++        |
++        |  /// Returns the current output variable.
++        |  def output() = if (direction == Direction.FORWARD) v2 else v1
++        |
++        |  /**
++        |   * Calculate the walkabout strength, the stay flag, and, if it is
++        |   * 'stay', the value for the current output of this
++        |   * constraint. Assume this constraint is satisfied.
++        |   */
++        |  def recalculate() {
++        |    val ihn = input()
++        |    val out = output()
++        |    out.walkStrength = Strength.weakest(strength, ihn.walkStrength)
++        |    out.stay = ihn.stay
++        |    if (out.stay) execute()
++        |  }
++        |
++        |  /// Record the fact that this constraint is unsatisfied.
++        |  def markUnsatisfied() {
++        |    direction = Direction.NONE
++        |  }
++        |
++        |  def inputsKnown(mark: Int): Boolean = {
++        |    val i = input()
++        |    i.mark == mark || i.stay || i.determinedBy == null
++        |  }
++        |
++        |  def removeFromGraph() {
++        |    if (v1 != null) v1.removeConstraint(this)
++        |    if (v2 != null) v2.removeConstraint(this)
++        |    direction = Direction.NONE
++        |  }
++        |}
++        |
++        |/**
++        | * Relates two variables by the linear scaling relationship: "v2 =
++        | * (v1 * scale) + offset". Either v1 or v2 may be changed to maintain
++        | * this relationship but the scale factor and offset are considered
++        | * read-only.
++        | */
++        |class ScaleConstraint(v1: Variable,
++        |                      scale: Variable,
++        |                      offset: Variable,
++        |                      v2: Variable,
++        |                      strength: Strength)(implicit planner: Planner)
++        |    extends BinaryConstraint(v1, v2, strength) {
++        |
++        |  /// Adds this constraint to the constraint graph.
++        |  override def addToGraph() {
++        |    super.addToGraph()
++        |    scale.addConstraint(this)
++        |    offset.addConstraint(this)
++        |  }
++        |
++        |  override def removeFromGraph() {
++        |    super.removeFromGraph()
++        |    if (scale != null) scale.removeConstraint(this)
++        |    if (offset != null) offset.removeConstraint(this)
++        |  }
++        |
++        |  override def markInputs(mark: Int) {
++        |    super.markInputs(mark)
++        |    scale.mark = mark
++        |    offset.mark = mark
++        |  }
++        |
++        |  /// Enforce this constraint. Assume that it is satisfied.
++        |  def execute() {
++        |    if (direction == Direction.FORWARD) {
++        |      v2.value = v1.value * scale.value + offset.value
++        |    } else {
++        |      // XXX: Truncates the resulting value
++        |      v1.value = (v2.value - offset.value) / scale.value
++        |    }
++        |  }
++        |
++        |  /**
++        |   * Calculate the walkabout strength, the stay flag, and, if it is
++        |   * 'stay', the value for the current output of this constraint. Assume
++        |   * this constraint is satisfied.
++        |   */
++        |  override def recalculate() {
++        |    val ihn = input()
++        |    val out = output()
++        |    out.walkStrength = Strength.weakest(strength, ihn.walkStrength)
++        |    out.stay = ihn.stay && scale.stay && offset.stay
++        |    if (out.stay) execute()
++        |  }
++        |
++        |}
++        |
++        |/**
++        | * Constrains two variables to have the same value.
++        | */
++        |class EqualityConstraint(v1: Variable, v2: Variable, strength: Strength)(
++        |    implicit planner: Planner)
++        |    extends BinaryConstraint(v1, v2, strength) {
++        |  /// Enforce this constraint. Assume that it is satisfied.
++        |  def execute() {
++        |    output().value = input().value
++        |  }
++        |}
++        |
++        |/**
++        | * A constrained variable. In addition to its value, it maintain the
++        | * structure of the constraint graph, the current dataflow graph, and
++        | * various parameters of interest to the DeltaBlue incremental
++        | * constraint solver.
++        | */
++        |class Variable(val name: String, var value: Int) {
++        |
++        |  val constraints              = new ListBuffer[Constraint]()
++        |  var determinedBy: Constraint = null
++        |  var mark                     = 0
++        |  var walkStrength: Strength   = WEAKEST
++        |  var stay                     = true
++        |
++        |  /**
++        |   * Add the given constraint to the set of all constraints that refer
++        |   * this variable.
++        |   */
++        |  def addConstraint(c: Constraint) {
++        |    constraints += c
++        |  }
++        |
++        |  /// Removes all traces of c from this variable.
++        |  def removeConstraint(c: Constraint) {
++        |    constraints -= c
++        |    if (determinedBy == c) determinedBy = null
++        |  }
++        |}
++        |
++        |class Planner {
++        |
++        |  var currentMark = 0
++        |
++        |  /**
++        |   * Attempt to satisfy the given constraint and, if successful,
++        |   * incrementally update the dataflow graph.  Details: If satifying
++        |   * the constraint is successful, it may override a weaker constraint
++        |   * on its output. The algorithm attempts to resatisfy that
++        |   * constraint using some other method. This process is repeated
++        |   * until either a) it reaches a variable that was not previously
++        |   * determined by any constraint or b) it reaches a constraint that
++        |   * is too weak to be satisfied using any of its methods. The
++        |   * variables of constraints that have been processed are marked with
++        |   * a unique mark value so that we know where we've been. This allows
++        |   * the algorithm to avoid getting into an infinite loop even if the
++        |   * constraint graph has an inadvertent cycle.
++        |   */
++        |  def incrementalAdd(c: Constraint) {
++        |    val mark       = newMark()
++        |    var overridden = c.satisfy(mark)
++        |    while (overridden != null) overridden = overridden.satisfy(mark)
++        |  }
++        |
++        |  /**
++        |   * Entry point for retracting a constraint. Remove the given
++        |   * constraint and incrementally update the dataflow graph.
++        |   * Details: Retracting the given constraint may allow some currently
++        |   * unsatisfiable downstream constraint to be satisfied. We therefore collect
++        |   * a list of unsatisfied downstream constraints and attempt to
++        |   * satisfy each one in turn. This list is traversed by constraint
++        |   * strength, strongest first, as a heuristic for avoiding
++        |   * unnecessarily adding and then overriding weak constraints.
++        |   * Assume: [c] is satisfied.
++        |   */
++        |  def incrementalRemove(c: Constraint) {
++        |    val out = c.output()
++        |    c.markUnsatisfied()
++        |    c.removeFromGraph()
++        |    val unsatisfied        = removePropagateFrom(out)
++        |    var strength: Strength = REQUIRED
++        |    do {
++        |      for (u <- unsatisfied) {
++        |        if (u.strength == strength) incrementalAdd(u)
++        |      }
++        |      strength = strength.nextWeaker
++        |    } while (strength != WEAKEST)
++        |  }
++        |
++        |  /// Select a previously unused mark value.
++        |  def newMark(): Int = {
++        |    currentMark += 1
++        |    currentMark
++        |  }
++        |
++        |  /**
++        |   * Extract a plan for resatisfaction starting from the given source
++        |   * constraints, usually a set of input constraints. This method
++        |   * assumes that stay optimization is desired; the plan will contain
++        |   * only constraints whose output variables are not stay. Constraints
++        |   * that do no computation, such as stay and edit constraints, are
++        |   * not included in the plan.
++        |   * Details: The outputs of a constraint are marked when it is added
++        |   * to the plan under construction. A constraint may be appended to
++        |   * the plan when all its input variables are known. A variable is
++        |   * known if either a) the variable is marked (indicating that has
++        |   * been computed by a constraint appearing earlier in the plan), b)
++        |   * the variable is 'stay' (i.e. it is a constant at plan execution
++        |   * time), or c) the variable is not determined by any
++        |   * constraint. The last provision is for past states of history
++        |   * variables, which are not stay but which are also not computed by
++        |   * any constraint.
++        |   * Assume: [sources] are all satisfied.
++        |   */
++        |  def makePlan(sources: Stack[Constraint]) = {
++        |    val mark = newMark()
++        |    val plan = new Plan()
++        |    val todo = sources
++        |    while (!todo.isEmpty) {
++        |      val c = todo.pop()
++        |      if (c.output().mark != mark && c.inputsKnown(mark)) {
++        |        plan.addConstraint(c)
++        |        c.output().mark = mark
++        |        addConstraintsConsumingTo(c.output(), todo)
++        |      }
++        |    }
++        |    plan
++        |  }
++        |
++        |  /**
++        |   * Extract a plan for resatisfying starting from the output of the
++        |   * given [constraints], usually a set of input constraints.
++        |   */
++        |  def extractPlanFromConstraints(constraints: Seq[Constraint]) = {
++        |    val sources = new Stack[Constraint]()
++        |    for (c <- constraints) {
++        |      // if not in plan already and eligible for inclusion.
++        |      if (c.isInput && c.isSatisfied()) sources.push(c)
++        |    }
++        |    makePlan(sources)
++        |  }
++        |
++        |  /**
++        |   * Recompute the walkabout strengths and stay flags of all variables
++        |   * downstream of the given constraint and recompute the actual
++        |   * values of all variables whose stay flag is true. If a cycle is
++        |   * detected, remove the given constraint and answer
++        |   * false. Otherwise, answer true.
++        |   * Details: Cycles are detected when a marked variable is
++        |   * encountered downstream of the given constraint. The sender is
++        |   * assumed to have marked the inputs of the given constraint with
++        |   * the given mark. Thus, encountering a marked node downstream of
++        |   * the output constraint means that there is a path from the
++        |   * constraint's output to one of its inputs.
++        |   */
++        |  def addPropagate(c: Constraint, mark: Int): Boolean = {
++        |    val todo = new Stack[Constraint]().push(c)
++        |    while (!todo.isEmpty) {
++        |      val d = todo.pop()
++        |      if (d.output().mark == mark) {
++        |        incrementalRemove(c)
++        |        return false
++        |      }
++        |      d.recalculate()
++        |      addConstraintsConsumingTo(d.output(), todo)
++        |    }
++        |    true
++        |  }
++        |
++        |  /**
++        |   * Update the walkabout strengths and stay flags of all variables
++        |   * downstream of the given constraint. Answer a collection of
++        |   * unsatisfied constraints sorted in order of decreasing strength.
++        |   */
++        |  def removePropagateFrom(out: Variable): Seq[Constraint] = {
++        |    out.determinedBy = null
++        |    out.walkStrength = WEAKEST
++        |    out.stay = true
++        |    val unsatisfied = new ListBuffer[Constraint]()
++        |    val todo        = new Stack[Variable]().push(out)
++        |    while (!todo.isEmpty) {
++        |      val v = todo.pop()
++        |      for (c <- v.constraints) {
++        |        if (!c.isSatisfied()) unsatisfied += c
++        |      }
++        |      val determining = v.determinedBy
++        |      for (next <- v.constraints) {
++        |        if (next != determining && next.isSatisfied()) {
++        |          next.recalculate()
++        |          todo.push(next.output())
++        |        }
++        |      }
++        |    }
++        |    unsatisfied
++        |  }
++        |
++        |  def addConstraintsConsumingTo(v: Variable, coll: Stack[Constraint]) {
++        |    val determining = v.determinedBy
++        |    for (c <- v.constraints) {
++        |      if (c != determining && c.isSatisfied()) coll.push(c)
++        |    }
++        |  }
++        |}
++        |
++        |/**
++        | * A Plan is an ordered list of constraints to be executed in sequence
++        | * to resatisfy all currently satisfiable constraints in the face of
++        | * one or more changing inputs.
++        | */
++        |class Plan {
++        |  private val list = new ListBuffer[Constraint]()
++        |
++        |  def addConstraint(c: Constraint) {
++        |    list += c
++        |  }
++        |
++        |  def execute() {
++        |    for (constraint <- list) {
++        |      constraint.execute()
++        |    }
++        |  }
++        |}""".stripMargin
++
++    withoutAndWith("deltablue.DeltaBlue$",
++            Driver(),
++            1,
++            sources) {
++      case (base, ic) =>
++        println("#" * 181)
++        println("Base:\n" + base)
++        println("IC  :\n" + ic)
++        println("#" * 181)
++    }
++  }
++}
